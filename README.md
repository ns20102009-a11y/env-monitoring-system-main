@ -0,0 +1,160 @@
# ðŸŒ Real-Time Environmental Monitoring System
> **Hackathon-Ready** | Python + Pathway Streaming + Streamlit Dashboard

---

## ðŸ—‚ï¸ Project Structure

```
project/
 â”œâ”€â”€ data_stream.py          â† Simulates sensor data (Kafka Producer equivalent)
 â”œâ”€â”€ monitoring_pipeline.py  â† Pathway streaming pipeline (core logic)
 â”œâ”€â”€ dashboard.py            â† Live Streamlit dashboard
 â”œâ”€â”€ requirements.txt        â† All dependencies
 â””â”€â”€ README.md               â† You are here!

# Auto-generated at runtime:
 â”œâ”€â”€ sensor_data.jsonl       â† Raw sensor readings (stream input)
 â””â”€â”€ processed_data.jsonl    â† Enriched data with alerts (stream output)
```

---

## ðŸš€ Quick Start (3 Terminals)

### Step 1 â€” Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 2 â€” Terminal 1: Start the Data Generator
```bash
python data_stream.py
```
You'll see sensor readings printing every 2 seconds. Leave this running.

### Step 3 â€” Terminal 2: Start the Pathway Pipeline
```bash
python monitoring_pipeline.py
```
Pathway watches the data file and processes each new reading in real-time.

### Step 4 â€” Terminal 3: Launch the Dashboard
```bash
streamlit run dashboard.py
```
Opens automatically at **http://localhost:8501** â€” refreshes every 3 seconds!

---

## ðŸ” Risk Detection Rules

| Metric      | Threshold | Status              | Safety Advice                        |
|-------------|-----------|---------------------|--------------------------------------|
| AQI         | > 150     | ðŸ”´ Unsafe Air       | Avoid outdoor activity               |
| AQI         | > 100     | ðŸŸ¡ Moderate         | Sensitive groups be cautious         |
| AQI         | â‰¤ 100     | ðŸŸ¢ Good             | Air quality is safe                  |
| Temperature | > 40Â°C    | ðŸ”´ Heat Risk        | Stay hydrated, avoid direct sun      |
| Temperature | > 35Â°C    | ðŸŸ¡ Warm             | Drink water regularly                |
| Temperature | â‰¤ 35Â°C    | ðŸŸ¢ Normal           | Temperature is comfortable           |
| Humidity    | > 80%     | ðŸ”´ High Moisture    | Risk of mold, heat stress            |
| Humidity    | > 60%     | ðŸŸ¡ Elevated         | Monitor for discomfort               |
| Humidity    | â‰¤ 60%     | ðŸŸ¢ Normal           | Humidity is comfortable              |

---

## âš¡ How Pathway Handles Streaming

Pathway treats data as a **live, continuously-updating table** â€” not a static file.

```
Traditional Batch:   Read file â†’ Process ALL rows â†’ Write output (one-shot)
Pathway Streaming:   Watch file â†’ Process EACH NEW ROW instantly â†’ Update output (continuous)
```

**Under the hood, Pathway:**
1. Opens the input file in *streaming mode*
2. Watches for new lines appended to the file
3. Triggers your transformation logic on each new row within milliseconds
4. Emits the enriched result to the output sink immediately
5. Keeps running forever â€” it never "finishes"

This is the same model used by Apache Kafka consumers.

---

## ðŸ”— Where Apache Kafka Fits

This project uses **files** to simulate the Kafka messaging pattern:

```
[data_stream.py]  â†’  sensor_data.jsonl  â†’  [Pathway]  â†’  processed_data.jsonl
  (Producer)           (Kafka Topic)        (Consumer)     (Output Topic)
```

**To upgrade to real Kafka** (minimal code change):

```python
# In monitoring_pipeline.py, replace:
sensor_stream = pw.io.jsonlines.read(INPUT_FILE, schema=SensorSchema, mode="streaming")

# With:
rdkafka_settings = {
    "bootstrap.servers": "localhost:9092",
    "group.id":          "env-monitor-group",
    "auto.offset.reset": "latest",
}
sensor_stream = pw.io.kafka.read(
    rdkafka_settings,
    topic="env-sensors",
    schema=SensorSchema,
    format="json"
)
```

**Full Apache Ecosystem Integration:**

| Component        | Role in This System                          |
|------------------|----------------------------------------------|
| Apache Kafka     | Message bus â€” replaces JSONL file transport  |
| Apache Flink     | Alternative stream processor to Pathway      |
| Apache Spark     | Batch analytics on historical sensor data    |
| Apache Airflow   | Schedule batch report generation             |
| Apache HBase     | Store long-term sensor history at scale      |

---

## ðŸ§© Extending This Project

**Add a new sensor metric** (e.g., COâ‚‚):
1. In `data_stream.py` â†’ add `"co2_ppm": random.randint(400, 2000)` to the reading dict
2. In `monitoring_pipeline.py` â†’ add `co2_ppm: int` to `SensorSchema` and a new detect function
3. In `dashboard.py` â†’ add a new `st.metric(...)` column

**Add email alerts:**
```python
import smtplib
if overall_status == "UNSAFE":
    # send_email_alert(...)
```

**Switch to a real database output:**
```python
# Replace pw.io.jsonlines.write with:
pw.io.postgres.write(enriched, connection_string="postgresql://...")
```

---

## ðŸ“¸ Dashboard Features

- âœ… Auto-refreshes every 3 seconds
- ðŸ“Š Live trend charts for all 3 metrics
- ðŸš¨ Color-coded alert banners (ðŸ”´ðŸŸ¡ðŸŸ¢)
- ðŸ“¡ Multi-sensor support (SENSOR_A/B/C)
- ðŸ“‹ Raw data table (expandable)
- âš¡ Pathway architecture explanation built-in

---

*Built for hackathons â€” extend freely!*
